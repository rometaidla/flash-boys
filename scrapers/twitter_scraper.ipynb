{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# script for scraping tweets\n",
    "# snscrape needs python >= 3.8\n",
    "#!pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "ticker = \"GME\"\n",
    "since = \"2021-01-01\"\n",
    "until = \"2021-01-21\" #exclusive\n",
    "folder = \"tweets\"\n",
    "\n",
    "for date in pd.date_range(since, until)[:-1]:\n",
    "    search = f'\"${ticker}\" lang:en since:{date.date()} until:{date.date() + pd.Timedelta(days=1)} -filter:replies'\n",
    "    print(f\"Starting scraping for day {date.date()} ...\")\n",
    "    print(\"Search query is:\", search)\n",
    "    # get_items() returns generator\n",
    "    scraped_tweets = sntwitter.TwitterSearchScraper(search).get_items()\n",
    "    try:\n",
    "        df = pd.DataFrame(scraped_tweets)[[\"url\", \"date\", \"content\"]]\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        filename = os.path.join(folder,f\"{ticker}_{date.date()}.csv\")\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Tweets saved to file {filename}\")\n",
    "        print(f\"Tweet dataframe shape is {df.shape}\")\n",
    "    except KeyError:\n",
    "        print(f\"No tweets for day {date.date()}\")\n",
    "\n",
    "    print(f\"Finished scraping for day {date.date()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "version": "3.8.1"
  },
  "orig_nbformat": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}